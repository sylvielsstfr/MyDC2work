{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CosmoDC2 - Hack on Halos - Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Clusters & Velocity Appendix: Peaks in the Halo mass distribution\n",
    "\n",
    "Author: Julien Peloton [@JulienPeloton](https://github.com/JulienPeloton)  \n",
    "Last Verifed to Run: 2019-01-04  \n",
    "Estimated running time: < 5 min.\n",
    "\n",
    "This notebook, with the help of Apache Spark, inspects the peaks found in the halo mass distribution in the companion notebook.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "If we look at the distribution of halo masses in cosmoDC2, all seem OK. But if we look at the same distribution after filtering objects according to the stellar mass, we start to see peaks in the distribution. These peaks are regularly spaced in log, and their position is independent on the stellar mass cut applied.\n",
    "\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- Main issue: https://github.com/LSSTDESC/DC2-analysis/issues/57\n",
    "- Potential update of the cosmoDC2 simulation: https://github.com/LSSTDESC/cosmodc2/issues/84\n",
    "\n",
    "**Logistics:** \n",
    "\n",
    "This notebook is intended to be run through the JupyterHub NERSC interface with the desc-pyspark kernel. The kernel is automatically installed in your environment when you use the kernel setup script:\n",
    "\n",
    "```bash\n",
    "source /global/common/software/lsst/common/miniconda/kernels/setup.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Generator, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf , PandasUDFType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark session started\n"
     ]
    }
   ],
   "source": [
    "# Initialise our Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "print(\"spark session started\")\n",
    "\n",
    "#usefull class to benchmark\n",
    "class Timer:\n",
    "    \"\"\" A simple class for printing elapsed time (s) since last call\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.t0 = time()\n",
    "    \n",
    "    def start(self):\n",
    "        self.t0 = time()\n",
    "        \n",
    "    def split(self):\n",
    "        t1 = time()\n",
    "        print(\"{:2.1f}s\".format(t1 - self.t0))\n",
    "\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CosmoDC2 data with Spark\n",
    "\n",
    "Apache Spark has no efficient PySpark connector to read data in hdf5 file. Therefore we first converted the cosmoDC2 data set into parquet (similar to what DPDD tools offer). For the purpose of this notebook, we only convert a few columns of interest. The file is accessible at NERSC for DESC members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRECATED: Use of this script to execute hdfs command is deprecated.\n",
      "Instead use the hdfs command for it.\n",
      "\n",
      "Found 5 items\n",
      "drwxr-xr-x   - stephane.plaszczynski lsst          0 2019-09-03 20:04 /lsst/DC2/cosmoDC2/cosmoDC2_v1.1.4_image.parquet\n",
      "drwxr-xr-x   - stephane.plaszczynski lsst          0 2019-10-16 10:52 /lsst/DC2/cosmoDC2/cosmoDC2_v1.1.4_image_double.parquet\n",
      "drwxr-xr-x   - stephane.plaszczynski lsst          0 2020-04-23 17:28 /lsst/DC2/cosmoDC2/cosmoDC2_v1.1.4_image_nofaint.parquet\n",
      "drwxr-xr-x   - stephane.plaszczynski lsst          0 2020-09-07 19:17 /lsst/DC2/cosmoDC2/shear_cosmoDC2\n",
      "drwxr-xr-x   - stephane.plaszczynski lsst          0 2019-04-16 18:40 /lsst/DC2/cosmoDC2/xyz_v1.1.4_hive\n"
     ]
    }
   ],
   "source": [
    "! hadoop dfs -ls /lsst/DC2/cosmoDC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Mag_true_g_lsst_z0: float (nullable = true)\n",
      " |-- Mag_true_z_lsst_z0: float (nullable = true)\n",
      " |-- ra: float (nullable = true)\n",
      " |-- mag_y: float (nullable = true)\n",
      " |-- mag_z: float (nullable = true)\n",
      " |-- size_true: float (nullable = true)\n",
      " |-- halo_id: long (nullable = true)\n",
      " |-- position_x: float (nullable = true)\n",
      " |-- mag_g: float (nullable = true)\n",
      " |-- Mag_true_u_lsst_z0: float (nullable = true)\n",
      " |-- mag_true_r: float (nullable = true)\n",
      " |-- position_angle_true: float (nullable = true)\n",
      " |-- mag_true_g: float (nullable = true)\n",
      " |-- stellar_mass: float (nullable = true)\n",
      " |-- Mag_true_y_lsst_z0: float (nullable = true)\n",
      " |-- position_y: float (nullable = true)\n",
      " |-- mag_true_i: float (nullable = true)\n",
      " |-- redshift: float (nullable = true)\n",
      " |-- Mag_true_i_lsst_z0: float (nullable = true)\n",
      " |-- mag_r: float (nullable = true)\n",
      " |-- mag_true_y: float (nullable = true)\n",
      " |-- dec: float (nullable = true)\n",
      " |-- mag_true_u: float (nullable = true)\n",
      " |-- Mag_true_r_lsst_z0: float (nullable = true)\n",
      " |-- mag_i: float (nullable = true)\n",
      " |-- position_z: float (nullable = true)\n",
      " |-- mag_u: float (nullable = true)\n",
      " |-- mag_true_z: float (nullable = true)\n",
      " |-- is_central: boolean (nullable = true)\n",
      "\n",
      "Number of rows: 2256249331\n",
      "17.2s\n"
     ]
    }
   ],
   "source": [
    "timer.start()\n",
    "\n",
    "# Path to cosmoDC2 (parquet format)\n",
    "filename = \"/lsst/DC2/cosmoDC2/cosmoDC2_v1.1.4_image.parquet\"\n",
    "#filename = \"/lsst/DC2/cosmoDC2/cosmoDC2_v1.1.4_image_double.parquet\"\n",
    "#filename = \"/lsst/DC2/cosmoDC2/cosmoDC2_v1.1.4_image_nofaint.parquet\"\n",
    "\n",
    "# Spark DataFrame\n",
    "df = spark.read.parquet(filename)\n",
    "\n",
    "# Le's inspect the schema of the data\n",
    "df.printSchema()\n",
    "\n",
    "# Number of objects in the catalog\n",
    "print(\"Number of rows: {}\".format(df.count()))\n",
    "\n",
    "timer.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation: selecting halos by their stellar mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reject synthetic halos - see for example discussion in \n",
    "# https://github.com/LSSTDESC/cosmodc2/issues/82\n",
    "# In addition we select halo members according to their stellar mass\n",
    "stellar_masses_cut = [1e9, 1e10, 5e10, 1e11]\n",
    "full_data = []\n",
    "for stellar_mass_cut in stellar_masses_cut:\n",
    "    df_filt = df.filter(\"halo_id > 0\").filter(\"stellar_mass > {}\".format(stellar_mass_cut))\n",
    "\n",
    "    # Group data by halos and compute the number of halo members\n",
    "    df_disp = df_filt.groupBy(\"halo_id\").count()\n",
    "\n",
    "    # Add back the original DataFrame columns\n",
    "    # and select only central member for halo \n",
    "    # (unique halo mass for a halo)\n",
    "    data_joined = df_filt.join(df_disp, \"halo_id\")\\\n",
    "        .filter(\"is_central == True\")\\\n",
    "        .select(\"stellar_mass\", 'count')\\\n",
    "        .dropna()\n",
    "\n",
    "    # Collect the data from the executors to the driver\n",
    "    data = data_joined.collect()\n",
    "    full_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halo mass distribution\n",
    "\n",
    "(for the version without cut, see the main notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 17})\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Histogram of halo masses ($n_{{gal}}/halo > 0$)\")\n",
    "\n",
    "# Plot peak locations (empirical!)\n",
    "for k in range(90):\n",
    "    plt.axvline(k*0.15, ls='--', color='k', alpha=0.5)\n",
    "\n",
    "# Plot halo mass data\n",
    "for index, stellar_mass_cut in enumerate(stellar_masses_cut):\n",
    "    mass, count = np.transpose(full_data[index])\n",
    "    print(r\"Number of entries ($M_*$ > {:.1e} $M_\\odot$): {}\".format(stellar_mass_cut, len(mass)))\n",
    "    plt.hist(np.log10(mass), bins=200, alpha=0.5, label='$M_*$ > {:.1e} $M_\\odot$'.format(stellar_mass_cut))\n",
    "    \n",
    "\n",
    "plt.xlim(10.3, 15)\n",
    "plt.xlabel(r'$\\log({\\rm M}_h \\, [{\\rm M}_\\odot])$')\n",
    "plt.yscale('log')\n",
    "plt.legend(title=\"Only central galaxies with:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The position $p$ of the peaks is independent of the cut on the stellar mass, and it seems to follow:\n",
    "\n",
    "$$ \\log(M_{h}^{p}) = 0.15 * p $$\n",
    "\n",
    "\n",
    "Let's plot the same distribution, but selecting only halos with at least 2 members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 17})\n",
    "\n",
    "mincount = 1\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Histogram of halo masses ($n_{{gal}}/halo >$  {})\".format(mincount))\n",
    "\n",
    "# Plot peak locations (empirical!)\n",
    "for k in range(90):\n",
    "    plt.axvline(k*0.15, ls='--', color='k', alpha=0.5)\n",
    "\n",
    "# Plot halo mass data\n",
    "for index, stellar_mass_cut in enumerate(stellar_masses_cut):\n",
    "    mass, count = np.transpose(full_data[index])\n",
    "    mask = count > mincount\n",
    "    print(r\"Number of entries ($M_*$ > {:.1e} $M_\\odot$): {}\".format(stellar_mass_cut, len(mass[mask])))\n",
    "    plt.hist(np.log10(mass[mask]), bins=200, alpha=0.5, label='$M_*$ > {:.1e} $M_\\odot$'.format(stellar_mass_cut))\n",
    "    \n",
    "\n",
    "plt.xlim(10.3, 15)\n",
    "plt.xlabel(r'$\\log({\\rm M}_h \\, [{\\rm M}_\\odot])$')\n",
    "plt.yscale('log')\n",
    "plt.legend(title=\"Only central galaxies with:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peaks are even sharper at low mass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is that expected?\n",
    "\n",
    "**Answer:** The saw tooth shape is indeed expected (but probably not wanted!) from the way N-body simulations are done. A detailed discussion can be found at https://github.com/LSSTDESC/DC2-analysis/issues/57, and an action item for the simulation has been opened at https://github.com/LSSTDESC/cosmodc2/issues/84."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving to cuts on the Magnitude\n",
    "\n",
    "It has been suggested to not use the stellar mass for selecting halos (not a direct observable), but rather a more physically motivated quantity like magnitudes/colors. In this part, we select the apparent magnitude, lensed, in i band. This might not be the best quantity to look at, but just want to play with something else than the stellar mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's select halo masses, and magnitudes (i, g, u) for \n",
    "# the central galaxy.\n",
    "data = df.filter(\"halo_id > 0\")\\\n",
    "    .filter(\"is_central == True\")\\\n",
    "    .select([\"stellar_mass\", \"mag_i\", \"mag_g\", \"mag_u\"])\\\n",
    "    .sample(fraction=0.05).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass, mag_i, mag_g, mag_u = np.transpose(data)\n",
    "print(\"Number of rows: {}\".format(len(mass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "joint_kws = dict(gridsize=200, mincnt=1)\n",
    "g = sns.jointplot(\n",
    "    np.log10(mass), \n",
    "    mag_i, \n",
    "    height=8, space=0.5,\n",
    "    kind='hex', color='k', \n",
    "    xlim=(10.5, 12), ylim=(20, 35),\n",
    "    joint_kws=joint_kws, \n",
    "    marginal_kws=dict(bins=200, rug=True))\n",
    "\n",
    "g.set_axis_labels(\n",
    "    r'$\\log({\\rm M}_h \\, [{\\rm M}_\\odot])$', \n",
    "    'Apparent magnitude, lensed, in i band (lsst)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hum, the stripes are still there... Let's have a look at 1D halo mass distribution as a function of magnitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reject synthetic halos - see for example discussion in \n",
    "# https://github.com/LSSTDESC/cosmodc2/issues/82\n",
    "# In addition we select halo members according to their stellar mass\n",
    "stellar_masses_cut = [25.0, 22.5, 20.0]\n",
    "full_data = []\n",
    "for stellar_mass_cut in stellar_masses_cut:\n",
    "    df_filt = df.filter(\"halo_id > 0\").filter(\"mag_i < {}\".format(stellar_mass_cut))\n",
    "\n",
    "    # Group data by halos and compute the number of halo members\n",
    "    df_disp = df_filt.groupBy(\"halo_id\").count()\n",
    "\n",
    "    # Add back the original DataFrame columns\n",
    "    # and select only central member for halo \n",
    "    # (unique halo mass for a halo)\n",
    "    data_joined = df_filt.join(df_disp, \"halo_id\")\\\n",
    "        .filter(\"is_central == True\")\\\n",
    "        .select(\"stellar_mass\", 'count')\\\n",
    "        .dropna()\n",
    "\n",
    "    # Collect the data from the executors to the driver\n",
    "    data = data_joined.collect()\n",
    "    full_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 17})\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Histogram of halo masses ($n_{{gal}}/halo > 0$)\")\n",
    "\n",
    "# Plot peak locations (empirical!)\n",
    "for k in range(90):\n",
    "    plt.axvline(k*0.15, ls='--', color='k', alpha=0.5)\n",
    "\n",
    "# Plot halo mass data\n",
    "for index, stellar_mass_cut in enumerate(stellar_masses_cut):\n",
    "    mass, count = np.transpose(full_data[index])\n",
    "    print(r\"Number of entries (mag_i_lsst < {}): {}\".format(stellar_mass_cut, len(mass)))\n",
    "    plt.hist(np.log10(mass), bins=200, alpha=0.5, label='mag_i_lsst < {}'.format(stellar_mass_cut))\n",
    "    \n",
    "\n",
    "plt.xlim(10.3, 15)\n",
    "plt.xlabel(r'$\\log({\\rm M}_h \\, [{\\rm M}_\\odot])$')\n",
    "plt.yscale('log')\n",
    "plt.legend(title=\"Only central galaxies with:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what is seen for cut on the stellar mass... According to Andrew Hearin in [#57](https://github.com/LSSTDESC/DC2-analysis/issues/57), this makes sense as\n",
    "\n",
    "```\n",
    "... in the cosmoDC2 model, restframe flux derives from stellar mass, \n",
    "which in turn drives from halo mass, so it is expected that this discreteness \n",
    "propagates through to these other variables.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
