{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Cl on galaxy overdensities on CosmoDC2\n",
    "\n",
    "- author : Sylvie Dagoret-Campagne\n",
    "- affliliation : IJCLab/in2p3/CNRS\n",
    "- creation date : July 29th 2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyarrow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, pandas_udf \n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "from pyspark.sql.types import IntegerType,FloatType\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is how we create a function ('Ang2Pix') that can be called by dataframes\n",
    "# it takes as input the \"ra\" and \"dec\" values (which are not very different from theta/phi)\n",
    "# and returns the pixel number (but as pandas series for efficiency)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import healpy as hp\n",
    "\n",
    "nside=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "npix = hp.nside2npix(nside)\n",
    "lmax = 3 * nside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ang2Pix_func(ra: pd.Series, dec: pd.Series) -> pd.Series:\n",
    "    return pd.Series(hp.ang2pix(nside,np.radians(90-dec),np.radians(ra)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ang2pix = pandas_udf(Ang2Pix_func, returnType=IntegerType())\n",
    "#gal = gal.withColumn(\"ihealpix\",pd_ang2pix(gal[\"RA\"],gal[\"DEC\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get parquet files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scan all availables files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_input_dir=\"/global/cfs/cdirs/lsst/shared/DC2-prod/Run2.2i/truth/galtruth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_list_of_files=os.listdir(the_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth_summary_hp9304.sqlite3',\n",
       " 'truth_summary_hp10194.sqlite3',\n",
       " 'truth_summary_hp9945.parquet',\n",
       " 'truth_summary_hp9939.parquet',\n",
       " 'truth_summary_hp9944.sqlite3']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_list_of_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_sorted_list_of_files=sorted(the_list_of_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter the good parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_files=[]\n",
    "for filename in the_sorted_list_of_files:\n",
    "    sel_filename=re.findall(\"^truth_summary_hp.*.parquet$\",filename)\n",
    "    if len(sel_filename) > 0:\n",
    "        selected_files.append(sel_filename[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth_summary_hp10066.parquet',\n",
       " 'truth_summary_hp10067.parquet',\n",
       " 'truth_summary_hp10068.parquet',\n",
       " 'truth_summary_hp10069.parquet',\n",
       " 'truth_summary_hp10070.parquet']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = [the_input_dir + \"/{}\".format(filename) for filename in selected_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialise our Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Read the data as DataFrame\n",
    "#df = spark.read.format(\"parquet\").load(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#InputPath = [base_dir + \"/dc2_object_run2.2i_dr6b_tract2897.parquet\",\n",
    "#             base_dir + \"/dc2_object_run2.2i_dr6b_tract2898.parquet\"]\n",
    "\n",
    "df = spark.read.parquet(*InputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DC2 Object catalog Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- host_galaxy: long (nullable = true)\n",
      " |-- ra: double (nullable = true)\n",
      " |-- dec: double (nullable = true)\n",
      " |-- redshift: float (nullable = true)\n",
      " |-- is_variable: integer (nullable = true)\n",
      " |-- is_pointsource: integer (nullable = true)\n",
      " |-- flux_u: float (nullable = true)\n",
      " |-- flux_g: float (nullable = true)\n",
      " |-- flux_r: float (nullable = true)\n",
      " |-- flux_i: float (nullable = true)\n",
      " |-- flux_z: float (nullable = true)\n",
      " |-- flux_y: float (nullable = true)\n",
      " |-- flux_u_noMW: float (nullable = true)\n",
      " |-- flux_g_noMW: float (nullable = true)\n",
      " |-- flux_r_noMW: float (nullable = true)\n",
      " |-- flux_i_noMW: float (nullable = true)\n",
      " |-- flux_z_noMW: float (nullable = true)\n",
      " |-- flux_y_noMW: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check what we have in the file\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gal=df.filter('is_pointsource == false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ang2pix = pandas_udf(Ang2Pix_func, returnType=IntegerType())\n",
    "df_gal_healpix = df_gal.withColumn(\"ihealpix\",pd_ang2pix(df_gal[\"ra\"],df_gal[\"dec\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- host_galaxy: long (nullable = true)\n",
      " |-- ra: double (nullable = true)\n",
      " |-- dec: double (nullable = true)\n",
      " |-- redshift: float (nullable = true)\n",
      " |-- is_variable: integer (nullable = true)\n",
      " |-- is_pointsource: integer (nullable = true)\n",
      " |-- flux_u: float (nullable = true)\n",
      " |-- flux_g: float (nullable = true)\n",
      " |-- flux_r: float (nullable = true)\n",
      " |-- flux_i: float (nullable = true)\n",
      " |-- flux_z: float (nullable = true)\n",
      " |-- flux_y: float (nullable = true)\n",
      " |-- flux_u_noMW: float (nullable = true)\n",
      " |-- flux_g_noMW: float (nullable = true)\n",
      " |-- flux_r_noMW: float (nullable = true)\n",
      " |-- flux_i_noMW: float (nullable = true)\n",
      " |-- flux_z_noMW: float (nullable = true)\n",
      " |-- flux_y_noMW: float (nullable = true)\n",
      " |-- ihealpix: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gal_healpix.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gal_healpix_small=df_gal_healpix.select('ra','dec','ihealpix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gal_healpix_small.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=df_gal_healpix_small.groupBy('ihealpix').count()\n",
    "m.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.orderBy('ihealpix', ascending=True).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get to python world (to Pandas) : \n",
    "# note that here is the action (lazy evaluation so far)\n",
    "p=m.toPandas()\n",
    "p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following doesn't has anything to do with spark (only Healpix)\n",
    "hpMap = np.zeros(hp.nside2npix(nside))\n",
    "#fill the map from the pandas object\n",
    "hpMap[p['ihealpix'].values]=p['count'].values\n",
    "#plot using standard healpy function\n",
    "hp.mollview(hpMap,cmap=\"jet\")\n",
    "hp.graticule(color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = hp.anafast(hpMap)\n",
    "ell = np.arange(len(cl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-pyspark",
   "language": "python",
   "name": "desc-pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
